{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otvFEiB8Eq45"
      },
      "source": [
        "#Scoring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJyAY28-E1vW"
      },
      "source": [
        "###Prerequisites"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code requires a fixed lmppl-main.zip library (included in repo). This notebook assumes that the archive is located in the same folder."
      ],
      "metadata": {
        "id": "jaBBvPgPIOr0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al3aq7EAjQ5H"
      },
      "outputs": [],
      "source": [
        "! pip install transformers\n",
        "! pip install torch mxnet-mkl\n",
        "! pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIgYh-zbQjcz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhBGUq0FLkUD"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"rubia.tsv\", sep='\\t')\n",
        "\n",
        "data.loc[(data['domain'] == 'nationality') & (data['task_type'] == 'freeform_enemy'), 'task_type'] = 'freeform_full'\n",
        "data.loc[(data['domain'] == 'class') & (data['task_type'] == 'template_poor'), 'task_type'] = 'template_wealth'\n",
        "data.loc[(data['domain'] == 'class') & (data['task_type'] == 'template_rich'), 'task_type'] = 'template_wealth'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB47I8-jIpIF"
      },
      "source": [
        "###Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wASvHAWWaZn"
      },
      "source": [
        "#####New LM-PPL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tL-rLc1tvw9p"
      },
      "outputs": [],
      "source": [
        "! unzip lmppl-main.zip\n",
        "! sudo apt-get install python3.10-dev\n",
        "\n",
        "sh = \"\"\"\n",
        "cd lmppl-main\n",
        "pip install .\n",
        "\"\"\"\n",
        "with open('script.sh', 'w') as file:\n",
        "  file.write(sh)\n",
        "\n",
        "! bash script.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1BgxXodCjod"
      },
      "outputs": [],
      "source": [
        "import lmppl\n",
        "\n",
        "import torch\n",
        "import transformers\n",
        "import difflib\n",
        "import string\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQ841qh4WiTb"
      },
      "source": [
        "####Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bulmimSaIwFq"
      },
      "source": [
        "The following functions serve to score all correct samples in the dataset with an PPL model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szOL9vtbIuEb"
      },
      "outputs": [],
      "source": [
        "def ppl_score_model(model, model_name, model_type, data): # device\n",
        "    vocab = None\n",
        "\n",
        "    if model_type == 'reccurent':\n",
        "        scorer = lmppl.LM(model)\n",
        "\n",
        "        pro_res = []\n",
        "        anti_res = []\n",
        "\n",
        "        for i, s in enumerate(data['pro-trope']):\n",
        "            pro_res.append(scorer.get_perplexity([s])[0])\n",
        "\n",
        "        for i, s in enumerate(data['anti-trope']):\n",
        "            anti_res.append(scorer.get_perplexity([s])[0])\n",
        "\n",
        "    else:\n",
        "        scorer = lmppl.MaskedLM(model)\n",
        "\n",
        "        pro_res = []\n",
        "        anti_res = []\n",
        "\n",
        "        for i, s in enumerate(data['pro-trope']):\n",
        "            pro_res.append(scorer.get_perplexity([s])[0])\n",
        "\n",
        "        for i, s in enumerate(data['anti-trope']):\n",
        "            anti_res.append(scorer.get_perplexity([s])[0])\n",
        "\n",
        "    data['ppl-pro-' + model_name] = pro_res\n",
        "    data['ppl-anti-' + model_name] = anti_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62PZ-ef6I3gF"
      },
      "outputs": [],
      "source": [
        "def gets_stats(model_name, metric='ppl', to_lists=False):\n",
        "    domains = []\n",
        "    tasks = []\n",
        "    results = []\n",
        "\n",
        "    for domain in np.unique(data['domain']):\n",
        "        data_cur = data[(data['domain'] == domain) &\n",
        "                        (data['task_type'] != 'freeform_gendergap') &\n",
        "                        (data['task_type'] != 'freeform_family_stereotype') &\n",
        "                        (data['task_type'] != 'freeform_prof_stereotype') &\n",
        "                        (data['task_type'] != 'freeform_prof_stereotype')]\n",
        "\n",
        "        if metric=='ppl':\n",
        "            cur_bias = len(data_cur[data_cur[metric + '-pro-' + model_name] <\n",
        "                        data_cur[metric + '-anti-' + model_name]]) / len(data_cur)\n",
        "        else:\n",
        "            cur_bias = len(data_cur[data_cur[metric + '-pro-' + model_name] >\n",
        "                        data_cur[metric + '-anti-' + model_name]]) / len(data_cur)\n",
        "\n",
        "        if not to_lists:\n",
        "            print(\"\\n=========================\")\n",
        "            print(domain, \"bias: %.3f\" %(cur_bias))\n",
        "        else:\n",
        "            domains.append(domain)\n",
        "            tasks.append('all')\n",
        "            results.append(cur_bias)\n",
        "\n",
        "        for task_type in np.unique(data[data['domain'] == domain]['task_type']):\n",
        "            data_cur = data[(data['domain'] == domain) &\n",
        "                            (data['task_type'] == task_type)]\n",
        "\n",
        "            if metric=='ppl':\n",
        "                cur_bias = len(data_cur[data_cur[metric + '-pro-' + model_name] <\n",
        "                            data_cur[metric + '-anti-' + model_name]]) / len(data_cur)\n",
        "            else:\n",
        "                cur_bias = len(data_cur[data_cur[metric + '-pro-' + model_name] >\n",
        "                            data_cur[metric + '-anti-' + model_name]]) / len(data_cur)\n",
        "\n",
        "            if not to_lists:\n",
        "                print('\\t', task_type, \"bias: %.3f\" %(cur_bias))\n",
        "            else:\n",
        "                domains.append(domain)\n",
        "                tasks.append(task_type)\n",
        "                results.append(cur_bias)\n",
        "\n",
        "    return domains, tasks, results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcM6dSF_I7SF"
      },
      "outputs": [],
      "source": [
        "def full_score(model, name, data, device='cuda'):\n",
        "    ppl_score_model(model, name, data, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1wWVLlNJAwS"
      },
      "outputs": [],
      "source": [
        "def get_stats_all(name):\n",
        "    domains, tasks, ppls = gets_stats(name, metric='ppl', to_lists=True)\n",
        "\n",
        "    res = pd.DataFrame()\n",
        "    res['Domain'] = domains\n",
        "    res['SubDomain'] = tasks\n",
        "    res['Model'] = [name] * len(res)\n",
        "    res['PPL-Score'] = ppls\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4Pdo9UYS9D9"
      },
      "outputs": [],
      "source": [
        "all_res = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnWTApc2I9-l"
      },
      "source": [
        "###Test models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yg0MJd7rLQe4"
      },
      "source": [
        "####RuGPT Large"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFGUKWIGWvKW"
      },
      "source": [
        "1. Large based on GPT2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAtB6NN8JDzS"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%%capture\n",
        "model = 'ai-forever/rugpt3large_based_on_gpt2'\n",
        "full_score(model, \"ruGPT-large\", 'reccurent', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m8A2YPMMZNP"
      },
      "outputs": [],
      "source": [
        "rugpt_large_res = get_stats_all(\"ruGPT-large\")\n",
        "rugpt_large_res.to_csv('ruGPT-large.tsv', sep='\\t')\n",
        "all_res.append(rugpt_large_res)\n",
        "rugpt_large_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU5HVMqgNup6"
      },
      "source": [
        "#### RuGPT Base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBfz__hjSQ2n"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%%capture\n",
        "model = 'ai-forever/rugpt3medium_based_on_gpt2'\n",
        "full_score(model, \"ruGPT-base\", 'reccurent', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klCHGDGkSQ8c"
      },
      "outputs": [],
      "source": [
        "rugpt_base_res = get_stats_all(\"ruGPT-base\")\n",
        "rugpt_base_res.to_csv('ruGPT-base.tsv', sep='\\t')\n",
        "all_res.append(rugpt_base_res)\n",
        "rugpt_base_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3tbkG-QS1RM"
      },
      "source": [
        "####XGLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SobDgj_PS507"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%%capture\n",
        "model = 'facebook/xglm-564M'\n",
        "full_score(model, \"XGLM\", 'reccurent', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84VKiBfoZCoa"
      },
      "outputs": [],
      "source": [
        "xglm_res = get_stats_all(\"XGLM\")\n",
        "xglm_res.to_csv('XGLM.tsv', sep='\\t')\n",
        "all_res.append(xglm_res)\n",
        "xglm_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qryJ5VdA1UbJ"
      },
      "source": [
        "####mGPT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTqbtDqU1UbO"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%%capture\n",
        "model = 'ai-forever/mGPT'\n",
        "full_score(model, \"mGPT\", 'reccurent', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lqdc-Snu1UbO"
      },
      "outputs": [],
      "source": [
        "mgpt_res = get_stats_all(\"mGPT\")\n",
        "mgpt_res.to_csv('mGPT.tsv', sep='\\t')\n",
        "all_res.append(mgpt_res)\n",
        "mgpt_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyryWLQCU1uy"
      },
      "source": [
        "#### AI Dungeon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDhnf0CaU1vK"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%%capture\n",
        "model = 'imperialwool/ai-dungeon-medium-rus'\n",
        "full_score(model, \"aiDungeon\", 'reccurent', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzUr1im3U1vM"
      },
      "outputs": [],
      "source": [
        "aidungeon_res = get_stats_all(\"aiDungeon\")\n",
        "aidungeon_res.to_csv('aiDungeon.tsv', sep='\\t')\n",
        "all_res.append(aidungeon_res)\n",
        "aidungeon_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L62wHC73hE8a"
      },
      "source": [
        "###Masked LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0GNYMeoXt33"
      },
      "source": [
        "#### ruBert base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GW2QCVCqXt39"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%%capture\n",
        "model = 'DeepPavlov/rubert-base-cased'\n",
        "full_score(model, \"rubert-base\", 'masked', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HudHtGrkXt39"
      },
      "outputs": [],
      "source": [
        "rubert_base_res = get_stats_all(\"rubert-base\")\n",
        "rubert_base_res.to_csv('rubert-base.tsv', sep='\\t')\n",
        "all_res.append(rubert_base_res)\n",
        "rubert_base_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrTm_SkCYack"
      },
      "source": [
        "#### Twitter bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnoPhtofYack"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%%capture\n",
        "model = 'Twitter/twhin-bert-large'\n",
        "full_score(model, \"twhin-bert\", 'masked', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFR1UC9CYacl"
      },
      "outputs": [],
      "source": [
        "twhin_bert_res = get_stats_all(\"twhin-bert\")\n",
        "twhin_bert_res.to_csv('twhin-bert.tsv', sep='\\t')\n",
        "all_res.append(twhin_bert_res)\n",
        "twhin_bert_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7CYiH-uY-D8"
      },
      "source": [
        "#### ruRoberta large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Whawu1iY-ED"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%%capture\n",
        "model = 'ai-forever/ruRoberta-large'\n",
        "full_score(model, \"ruRoberta-large\", 'masked', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1o-14PIY-ED"
      },
      "outputs": [],
      "source": [
        "ruroberta_large_res = get_stats_all(\"ruRoberta-large\")\n",
        "ruroberta_large_res.to_csv('ruRoberta-large.tsv', sep='\\t')\n",
        "all_res.append(ruroberta_large_res)\n",
        "ruroberta_large_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_-43G7xz1_W"
      },
      "source": [
        "#### ruBert large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceo6-m9gz1_d"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%%capture\n",
        "model = 'ai-forever/ruBert-large'\n",
        "full_score(model, \"ruBert-large\", 'masked', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJRruCG9z1_d"
      },
      "outputs": [],
      "source": [
        "rubert_large_res = get_stats_all(\"ruBert-large\")\n",
        "rubert_large_res.to_csv('ruBert-large.tsv', sep='\\t')\n",
        "all_res.append(rubert_large_res)\n",
        "rubert_large_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ch0cK490rJ9"
      },
      "source": [
        "#### XLM Roberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQg5WpK_0rKE"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "%%capture\n",
        "model = 'xlm-roberta-large'\n",
        "full_score(model, \"xlm-roberta-large\", 'masked', data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTBHr1L-0rKE"
      },
      "outputs": [],
      "source": [
        "xlm_large_res = get_stats_all(\"xlm-roberta-large\")\n",
        "xlm_large_res.to_csv('xlm-roberta-large.tsv', sep='\\t')\n",
        "all_res.append(xlm_large_res)\n",
        "xlm_large_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-akMBxnMShc"
      },
      "source": [
        "### All results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9fHp4VlMR6a"
      },
      "source": [
        "In this part we aggregate the results across several models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTD1eIdkLZjP"
      },
      "outputs": [],
      "source": [
        "table_res = pd.concat(all_res).reset_index()\n",
        "table_res = table_res.drop(columns=['index'])\n",
        "data.to_csv('scored_data.tsv', sep=\"\\t\")\n",
        "table_res.to_csv('statistics.tsv', sep=\"\\t\")\n",
        "table_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Is-jCaE2MlFV"
      },
      "outputs": [],
      "source": [
        "scores = []\n",
        "\n",
        "for i in range(len(table_res)):\n",
        "  scores.append(table_res['PPL-Score'][i])\n",
        "\n",
        "table_res['Score'] = scores\n",
        "main_res = table_res[['Domain', 'SubDomain', 'Model', 'Score']]\n",
        "main_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYcltlhtMsbT"
      },
      "source": [
        "We also convert them into a more readable format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaEKpXkcMqFQ"
      },
      "outputs": [],
      "source": [
        "model_list = np.unique(main_res['Model'])\n",
        "model_scores = []\n",
        "\n",
        "for cur_model in model_list:\n",
        "    model_res = main_res[main_res['Model'] == cur_model].reset_index()\n",
        "    scores = model_res['Score']\n",
        "    domains = model_res['Domain']\n",
        "    subdomains = model_res['SubDomain']\n",
        "    model_scores.append(scores)\n",
        "\n",
        "ans = pd.DataFrame()\n",
        "ans['Domain'] = domains\n",
        "ans['Subdomain'] = subdomains\n",
        "\n",
        "for i in range(len(model_list)):\n",
        "    ans[model_list[i]] = model_scores[i]\n",
        "\n",
        "ans.to_csv('model_scores.tsv', sep=\"\\t\")\n",
        "ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xmcm67WaMveU"
      },
      "outputs": [],
      "source": [
        "for i in range(len(model_list)):\n",
        "    ans[model_list[i]] = ans[model_list[i]].apply(lambda x: round(x * 100, 1))\n",
        "\n",
        "ans"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans.to_csv('statistics.tsv', sep='\\t')"
      ],
      "metadata": {
        "id": "IqrhQDLaoYpM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "NB47I8-jIpIF",
        "7wASvHAWWaZn"
      ],
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}